{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Google Colab (Skip locally)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mount your Google Drive\n",
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from google.colab import drive\n",
    "import sys\n",
    "import os\n",
    "import shutil\n",
    "import warnings\n",
    "\n",
    "drive.mount('/content/gdrive')\n",
    "\n",
    "folder = \"/content/gdrive/MyDrive/IFT6135/HW1_2025/assignment1_release\" #@param {type:\"string\"}\n",
    "!ln -Ts \"$folder\" /content/assignment 2> /dev/null\n",
    "\n",
    "# Add the assignment folder to Python path\n",
    "if '/content/assignment' not in sys.path:\n",
    "  sys.path.insert(0, '/content/assignment')\n",
    "\n",
    "# Check if CUDA is available\n",
    "import torch\n",
    "if not torch.cuda.is_available():\n",
    "  warnings.warn('CUDA is not available.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports & Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import warnings\n",
    "\n",
    "from main import train_models\n",
    "from arguments import Arguments\n",
    "import os\n",
    "from plotter import generate_plots\n",
    "\n",
    "models = ['lstm', 'gpt']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiment 1 (Sanity Check)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model 1/2\n",
      "========================================\n",
      "log_dir : logs/experiment1\n",
      "n_steps : 500\n",
      "model : lstm\n",
      "exp_name : lstm\n",
      "exp_id : 0\n",
      "seed : 0\n",
      "checkpoint_path: logs/experiment1\\lstm\\0\n",
      "dataset_size: 480\n",
      "========================================\n",
      "Number of training epochs (500) & steps (500)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   1% |          | 3/500 [ 7.10it/s, step=3, loss=3.44396, lr=0.001]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train loss : 3.49893 | Train accuracy : 0.00000 | Test loss : 3.50019 | Test accuracy : 0.00000 | lr = 0.00100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  20% |██        | 101/500 [ 9.96it/s, step=102, loss=1.70876, lr=0.001]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train loss : 1.70979 | Train accuracy : 0.04583 | Test loss : 1.76863 | Test accuracy : 0.02079 | lr = 0.00100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  40% |████      | 201/500 [ 7.33it/s, step=202, loss=0.89884, lr=0.001]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train loss : 0.91950 | Train accuracy : 0.66042 | Test loss : 2.69184 | Test accuracy : 0.00000 | lr = 0.00100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  60% |██████    | 301/500 [ 8.18it/s, step=301, loss=0.06859, lr=0.001]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train loss : 0.06859 | Train accuracy : 1.00000 | Test loss : 3.61786 | Test accuracy : 0.00208 | lr = 0.00100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  80% |████████  | 402/500 [ 8.02it/s, step=402, loss=0.02783, lr=0.001]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train loss : 0.02796 | Train accuracy : 1.00000 | Test loss : 3.69963 | Test accuracy : 0.00416 | lr = 0.00100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100% |██████████| 500/500 [ 8.39it/s, step=500, loss=0.01980, lr=0.001]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train loss : 0.01975 | Train accuracy : 1.00000 | Test loss : 3.64438 | Test accuracy : 0.00416 | lr = 0.00100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model 2/2\n",
      "========================================\n",
      "log_dir : logs/experiment1\n",
      "n_steps : 500\n",
      "model : lstm\n",
      "exp_name : lstm\n",
      "exp_id : 1\n",
      "seed : 42\n",
      "checkpoint_path: logs/experiment1\\lstm\\1\n",
      "dataset_size: 480\n",
      "========================================\n",
      "Number of training epochs (500) & steps (500)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0% |          | 2/500 [ 4.81it/s, step=2, loss=3.54585, lr=0.001]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train loss : 3.54585 | Train accuracy : 0.01250 | Test loss : 3.54366 | Test accuracy : 0.01663 | lr = 0.00100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  20% |██        | 102/500 [ 8.85it/s, step=102, loss=1.69919, lr=0.001]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train loss : 1.70050 | Train accuracy : 0.07083 | Test loss : 1.76654 | Test accuracy : 0.00832 | lr = 0.00100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  40% |████      | 200/500 [ 7.25it/s, step=201, loss=0.93105, lr=0.001]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train loss : 0.93105 | Train accuracy : 0.65208 | Test loss : 2.59708 | Test accuracy : 0.00000 | lr = 0.00100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  60% |██████    | 300/500 [ 8.46it/s, step=301, loss=0.07089, lr=0.001]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train loss : 0.07089 | Train accuracy : 1.00000 | Test loss : 3.44532 | Test accuracy : 0.00208 | lr = 0.00100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  80% |████████  | 400/500 [ 4.57it/s, step=400, loss=0.02697, lr=0.001]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train loss : 0.02683 | Train accuracy : 1.00000 | Test loss : 3.51803 | Test accuracy : 0.00416 | lr = 0.00100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100% |██████████| 500/500 [ 7.81it/s, step=500, loss=0.01865, lr=0.001]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train loss : 0.01860 | Train accuracy : 1.00000 | Test loss : 3.46558 | Test accuracy : 0.00624 | lr = 0.00100\n",
      "Model 1/2\n",
      "logs/experiment1\\lstm\\0\n",
      "Model 2/2\n",
      "logs/experiment1\\lstm\\1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "too many values to unpack (expected 3)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 10\u001b[0m\n\u001b[0;32m      7\u001b[0m     args\u001b[38;5;241m.\u001b[39mmodel \u001b[38;5;241m=\u001b[39m model\n\u001b[0;32m      9\u001b[0m     args\u001b[38;5;241m.\u001b[39mexp_name \u001b[38;5;241m=\u001b[39m model\n\u001b[1;32m---> 10\u001b[0m     results[model] \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_models\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     12\u001b[0m generate_plots(results, save_path\u001b[38;5;241m=\u001b[39margs\u001b[38;5;241m.\u001b[39mlog_dir, mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstd\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\fwilh\\Desktop\\IFT6135-HW2\\src\\main.py:101\u001b[0m, in \u001b[0;36mtrain_models\u001b[1;34m(args, seeds, rseeds)\u001b[0m\n\u001b[0;32m     99\u001b[0m \u001b[38;5;66;03m# Plots for all runs of one configuration\u001b[39;00m\n\u001b[0;32m    100\u001b[0m save_path \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(args\u001b[38;5;241m.\u001b[39mlog_dir, args\u001b[38;5;241m.\u001b[39mexp_name, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mplots\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m--> 101\u001b[0m \u001b[43mgenerate_plots\u001b[49m\u001b[43m(\u001b[49m\u001b[43m{\u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mall_metrics\u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msave_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msave_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstd\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    103\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m all_models_per_trials, all_metrics, all_checkpoint_paths\n",
      "File \u001b[1;32mc:\\Users\\fwilh\\Desktop\\IFT6135-HW2\\src\\plotter.py:104\u001b[0m, in \u001b[0;36mgenerate_plots\u001b[1;34m(new_data, save_path, mode, seed_index)\u001b[0m\n\u001b[0;32m    101\u001b[0m plt\u001b[38;5;241m.\u001b[39mfigure()\n\u001b[0;32m    102\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m exp_name, exp_val \u001b[38;5;129;01min\u001b[39;00m new_data\u001b[38;5;241m.\u001b[39mitems():\n\u001b[0;32m    103\u001b[0m     \u001b[38;5;66;03m# Unpack experiment data: file_paths, metrics, and run_dirs.\u001b[39;00m\n\u001b[1;32m--> 104\u001b[0m     file_paths, metrics, run_dirs \u001b[38;5;241m=\u001b[39m exp_val\n\u001b[0;32m    105\u001b[0m     steps_runs \u001b[38;5;241m=\u001b[39m metrics[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mall_steps\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m    106\u001b[0m     y_values_runs \u001b[38;5;241m=\u001b[39m metrics[data_type][metric]\n",
      "\u001b[1;31mValueError\u001b[0m: too many values to unpack (expected 3)"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "args = Arguments()\n",
    "args.log_dir = \"logs/experiment1\"\n",
    "args.n_steps = 500\n",
    "\n",
    "results = {}\n",
    "for model in models:\n",
    "    args.model = model\n",
    "    \n",
    "    args.exp_name = model\n",
    "    _, results[model], _ = train_models(args)\n",
    "\n",
    "generate_plots(results, save_path=args.log_dir, mode=\"std\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiment 2 (Scaling Data Size : Training Ratio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "args = Arguments()\n",
    "args.log_dir = \"logs/experiment2\"\n",
    "\n",
    "results = {}\n",
    "for model in models:\n",
    "    args.model = model\n",
    "    args.log_dir = os.path.join(args.log_dir, model)\n",
    "    for r in [0.1, 0.3, 0.5, 0.7, 0.9]:\n",
    "        args.r_train = r\n",
    "        \n",
    "        args.exp_name = f\"{model}_r_{r}\"\n",
    "        results[model] = train_models(args)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiment 3 (Scaling Data Size : P)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "args = Arguments()\n",
    "args.log_dir = \"logs/experiment3\"\n",
    "\n",
    "args.p = 11\n",
    "# todo: add the rest of the arguments\n",
    "\n",
    "results = {}\n",
    "for model in models:\n",
    "    args.model = model\n",
    "    \n",
    "    args.exp_name = model\n",
    "    results[model] = train_models(args)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiment 4 (Scaling Model Size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "args = Arguments()\n",
    "args.log_dir = \"logs/experiment4\"\n",
    "\n",
    "for model in models:\n",
    "    args.model = model\n",
    "    args.log_dir = os.path.join(args.log_dir, model)\n",
    "    for L in [1, 2, 3]:\n",
    "        args.num_layers = L\n",
    "        for d in [2**6, 2**7, 2**8]:\n",
    "            args.embedding_size = d\n",
    "            args.hidden_size = d\n",
    "\n",
    "            args.exp_name = f\"{model}_L_{L}_d_{d}\"\n",
    "            train_models(args)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiment 5 (Scaling Compute)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "args = Arguments()\n",
    "args.log_dir = \"logs/experiment5\"\n",
    "\n",
    "for model in models:\n",
    "    args.model = model\n",
    "    args.log_dir = os.path.join(args.log_dir, model)\n",
    "    for B in [2**5, 2**6, 2**7, 2**8, 2**9]:\n",
    "        args.batch_size = B\n",
    "\n",
    "        args.exp_name = f\"{model}_B_{B}\"\n",
    "        train_models(args)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiment 6 (Regularisation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "args = Arguments()\n",
    "args.log_dir = \"logs/experiment6\"\n",
    "\n",
    "for model in models:\n",
    "    args.model = model\n",
    "    args.log_dir = os.path.join(args.log_dir, model)\n",
    "    for wd in [0.25, 0.5, 0.75, 1.0]:\n",
    "        args.weight_decay = wd\n",
    "\n",
    "        args.exp_name = f\"{model}_wd_{wd}\"\n",
    "        train_models(args)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ift",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
